{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from ast import literal_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in cleaned movies, preprocessed movies, and user preferences\n",
    "movie_data = pd.read_csv('data/preprocessed_movies.csv')\n",
    "user_data = ['Comedy, Romance, Will Smith, skip, skip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendation(movie_data: pd.DataFrame, user_data: list):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        movie_data (df): dataframe containing movie attributes\n",
    "        user_data (list): list containing user movie preferences\n",
    "    \"\"\"\n",
    "    # Create copy of last row of dataset which will be used for user inputs\n",
    "    new_row = movie_data.iloc[-1:, :].copy(deep=True)\n",
    "    \n",
    "    # Add user input to the new row\n",
    "    new_row.iloc[-1] = \" \".join([str.lower(x) for x in user_data])\n",
    "    \n",
    "    # Add new row to the dataset\n",
    "    movie_data = movie_data.append(new_row)\n",
    "    \n",
    "    # Vectorize matrix\n",
    "    count = CountVectorizer(stop_words='english')\n",
    "    count_matrix = count.fit_transform(movie_data.soup)\n",
    "    \n",
    "    # Cosine Similarity to get a similarity matrix\n",
    "    cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "    \n",
    "    # Sort similarities from highest to lowest\n",
    "    scores = list(enumerate(cosine_sim[-1,:]))\n",
    "    scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Match similarities\n",
    "    ranked_titles = []\n",
    "    for i in range(1,6):\n",
    "        indx = scores[i][0]\n",
    "        ranked_titles.append([movie_data['Series_Title'].iloc[indx], movie_data['Genre'].iloc[indx], movie_data['IMDB_Rating'].iloc[indx]])\n",
    "    \n",
    "    return ranked_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/04/382s5ryn4cg90lmcyzj298g00000gn/T/ipykernel_24061/2973754676.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  movie_data = movie_data.append(new_row)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['It Happened One Night', 'comedy  romance', 8.1],\n",
       " ['Roman Holiday', 'comedy  romance', 8.0],\n",
       " ['The Philadelphia Story', 'comedy  romance', 7.9],\n",
       " ['Vicky Donor', 'comedy  romance', 7.8],\n",
       " ['Am√©lie', 'comedy  romance', 8.3]]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_recommendation(movie_data=movie_data, user_data=user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
